{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Model - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roberto/Documents/virtualenv/venv04/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import scipy\n",
    "import keras\n",
    "from keras.optimizers import  Adam\n",
    "from random import shuffle\n",
    "import sys\n",
    "MY_UTILS_PATH = \"../Modules/\"\n",
    "if not MY_UTILS_PATH in sys.path:\n",
    "    sys.path.append(MY_UTILS_PATH)\n",
    "import frequency_spatial_network as fsnet  \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/roberto/DATA/GDrive/MR-Data/Normative-Raw-Data/Train/e14292s3_P85504.7.npy\n",
      "25\n",
      "\n",
      "/media/roberto/DATA/GDrive/MR-Data/Normative-Raw-Data/Val/e14553s5_P44544.7.npy\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Train Set \n",
    "train_path = \"/media/roberto/DATA/GDrive/MR-Data/Normative-Raw-Data/Train/*.npy\"\n",
    "kspace_files_train = np.asarray(glob.glob(train_path))\n",
    "\n",
    "# Validation set\n",
    "val_path = \"/media/roberto/DATA/GDrive/MR-Data/Normative-Raw-Data/Val/*.npy\"\n",
    "kspace_files_val = np.asarray(glob.glob(val_path))\n",
    "\n",
    "indexes = np.arange(kspace_files_train.size,dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "kspace_files_train = kspace_files_train[indexes]\n",
    "\n",
    "\n",
    "print kspace_files_train[-1]\n",
    "print len(kspace_files_train)\n",
    "print \n",
    "print kspace_files_val[-1]\n",
    "print len(kspace_files_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling: 0.822937011719\n",
      "Mask type: bool\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "under_rate = '20'\n",
    "imshape = (256,256)\n",
    "norm = np.sqrt(imshape[0]*imshape[1])\n",
    "nchannels = 2 #complex data real + imag\n",
    "\n",
    "# undersampling patterns - uncentred k-space\n",
    "var_sampling_mask = np.load(\"../Data/sampling_mask_\" + under_rate + \"perc.npy\")\n",
    "\n",
    "print \"Undersampling:\", 1.0*var_sampling_mask.sum()/var_sampling_mask.size\n",
    "print \"Mask type:\",  var_sampling_mask.dtype\n",
    "plt.figure()\n",
    "plt.imshow(~var_sampling_mask,cmap = \"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples 4254\n"
     ]
    }
   ],
   "source": [
    "# Get number of samples\n",
    "ntrain = 0\n",
    "for ii in xrange(len(kspace_files_train)):\n",
    "    ntrain += np.load(kspace_files_train[ii]).shape[0]\n",
    "\n",
    "# Load train data    \n",
    "rec_train = np.zeros((ntrain,imshape[0],imshape[1],2))\n",
    "kspace_train = np.zeros((ntrain,imshape[0],imshape[1],2))\n",
    "aux_counter = 0\n",
    "for ii in xrange(len(kspace_files_train)):\n",
    "     aux_kspace = np.load(kspace_files_train[ii])/norm\n",
    "     aux = aux_kspace.shape[0]   \n",
    "     aux2 = np.fft.ifft2(aux_kspace[:,:,:,0]+1j*aux_kspace[:,:,:,1])\n",
    "     rec_train[aux_counter:aux_counter+aux,:,:,0] = aux2.real\n",
    "     rec_train[aux_counter:aux_counter+aux,:,:,1] = aux2.imag\n",
    "     kspace_train[aux_counter:aux_counter+aux,:,:,0] = aux_kspace[:,:,:,0]\n",
    "     kspace_train[aux_counter:aux_counter+aux,:,:,1] = aux_kspace[:,:,:,1]\n",
    "     aux_counter+=aux\n",
    "\n",
    "# Shuffle training    \n",
    "indexes = np.arange(rec_train.shape[0],dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "rec_train = rec_train[indexes]\n",
    "\n",
    "kspace_train[:,var_sampling_mask,:] = 0 # undersample k-space\n",
    "\n",
    "# save k-space and image domain stats\n",
    "stats = np.zeros(4)\n",
    "stats[0] = kspace_train.mean()\n",
    "stats[1] = kspace_train.std()\n",
    "aux = np.abs(rec_train[:,:,:,0] +1j*rec_train[:,:,:,1])\n",
    "stats[2] = aux.mean()\n",
    "stats[3] = aux.std()\n",
    "np.save(\"../Data/stats_fs_unet_norm_\" + under_rate + \".npy\",stats)\n",
    "\n",
    "print \"Number of training samples\", rec_train.shape[0]\n",
    "kspace_train = 0 # release memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples 1700\n",
      "Kspace under stats -1.2661701795258377e-05 0.9676880783869398\n",
      "Kspace full stats 0.09448459411815575 1102.6839607341497\n",
      "Rec stats 4.026266893604267 4.571199197368038\n"
     ]
    }
   ],
   "source": [
    "# Get number of samples\n",
    "nval = 0\n",
    "for ii in xrange(len(kspace_files_val)):\n",
    "    nval += np.load(kspace_files_val[ii]).shape[0]\n",
    "\n",
    "kspace_val = np.zeros((nval,imshape[0],imshape[1],nchannels))\n",
    "rec_val = np.zeros((nval,imshape[0],imshape[1],1))\n",
    "aux_counter = 0\n",
    "for ii in xrange(len(kspace_files_val)):\n",
    "    aux_kspace = np.load(kspace_files_val[ii])/norm\n",
    "    aux = aux_kspace.shape[0]   \n",
    "    kspace_val[aux_counter:aux_counter+aux] = aux_kspace\n",
    "    rec_val[aux_counter:aux_counter+aux,:,:,0] = \\\n",
    "    np.abs(np.fft.ifft2(aux_kspace[:,:,:,0]+1j*aux_kspace[:,:,:,1]))\n",
    "    aux_counter+=aux\n",
    "\n",
    "# Undersampling kspace\n",
    "kspace_val2 = kspace_val.copy()\n",
    "kspace_val[:,var_sampling_mask,:] = 0\n",
    "kspace_val = (kspace_val-stats[0])/stats[1]\n",
    "\n",
    "print \"Number of samples\", kspace_val.shape[0]\n",
    "print \"Kspace under stats\", kspace_val.mean(),kspace_val.std()\n",
    "print \"Kspace full stats\", kspace_val2.mean(),kspace_val2.std()\n",
    "print \"Rec stats\", rec_val.mean(),rec_val.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 2)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 48) 2448        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 48) 57648       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 48) 57648       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 48) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 76864       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 102464      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 102464      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 128)  204928      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 128)  409728      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 128)  409728      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 256)  819456      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 256)  1638656     conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 256)  1638656     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  1228928     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 128)  409728      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 128)  409728      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 307264      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 64) 102464      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 64) 102464      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 112 0           up_sampling2d_3[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 48) 134448      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 48) 57648       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 48) 57648       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 2)  98          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256, 256, 2)  0           conv2d_22[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256, 256, 2)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 256, 256, 1)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 256, 256, 1)  0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 48) 480         lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 48) 0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 64) 27712       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 128)  73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 256)  295168      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 384)  0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 128 0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_5[0][0]            \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 256, 256, 112 0           up_sampling2d_6[0][0]            \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 256, 256, 48) 48432       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 256, 256, 48) 20784       conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 256, 256, 1)  49          conv2d_43[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,331,299\n",
      "Trainable params: 11,331,299\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "epochs = 250\n",
    "batch_size= 16\n",
    "model = fsnet.fs_rec_unet_norm_res(stats[0],stats[1],stats[2],stats[3],\\\n",
    "                                   kshape = (5,5),kshape2=(3,3))\n",
    "opt = Adam(decay = 1e-7)\n",
    "model.compile(loss = [fsnet.nrmse,fsnet.nrmse],optimizer=opt, loss_weights=[0.001, 0.999])\n",
    "\n",
    "model_name = \"../Models/double_unet_\" + under_rate + \".hdf5\"\n",
    "if os.path.isfile(model_name):\n",
    "    model.load_weights(model_name)\n",
    "\n",
    "print model.summary()\n",
    "\n",
    "# Early stopping callback to shut down training after\n",
    "#10 epochs with no improvement\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                                       patience=20, \n",
    "                                       verbose=0, mode='min')\n",
    "\n",
    "# Checkpoint callback to save model  along the epochs\n",
    "checkpoint = ModelCheckpoint(model_name, mode = 'min', \\\n",
    "                             monitor='val_loss',verbose=0,\\\n",
    "                             save_best_only=True, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roberto/Documents/virtualenv/venv04/local/lib/python2.7/site-packages/keras/preprocessing/image.py:748: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (4254, 256, 256, 2) (2 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n",
      "/home/roberto/Documents/virtualenv/venv04/local/lib/python2.7/site-packages/keras/preprocessing/image.py:935: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (4254, 256, 256, 2) (2 channels).\n",
      "  ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "seed = 905\n",
    "image_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.075,\n",
    "        height_shift_range=0.075,\n",
    "        shear_range=0.25,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect')\n",
    "\n",
    "\n",
    "image_datagen.fit(rec_train, augment=True, seed=seed)\n",
    "image_generator = image_datagen.flow(rec_train,batch_size = batch_size,seed = seed)\n",
    "\n",
    "#mask = np.concatenate((var_sampling_mask[:,:,np.newaxis],var_sampling_mask[:,:,np.newaxis]),axis = -1).astype(np.float32) \n",
    "# function to merge generators\n",
    "#mask_batch = np.zeros((batch_size,mask.shape[0],mask.shape[1],mask.shape[2]))\n",
    "#mask_batch[:] = mask\n",
    "#mask2 = K.variable(value = mask_batch)\n",
    "def combine_generator(gen1,under_mask,stats):\n",
    "    while True:\n",
    "        rec = gen1.next()\n",
    "        kspace = np.fft.fft2(rec[:,:,:,0]+1j*rec[:,:,:,1])\n",
    "        kspace2 = np.zeros((kspace.shape[0],kspace.shape[1],kspace.shape[2],2))\n",
    "        kspace2[:,:,:,0] = kspace.real\n",
    "        kspace2[:,:,:,1] = kspace.imag\n",
    "        kspace_under = kspace2.copy()\n",
    "        kspace_under[:,var_sampling_mask,:] = 0\n",
    "        kspace_under = (kspace_under-stats[0])/stats[1]\n",
    "        rec = np.abs(rec[:,:,:,0]+1j*rec[:,:,:,1])[:,:,:,np.newaxis]\n",
    "        yield(kspace_under, [kspace2,rec])\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "combined = combine_generator(image_generator, var_sampling_mask,stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/250\n",
      "265/265 [==============================] - 398s 2s/step - loss: 0.0823 - lambda_1_loss: 0.2287 - conv2d_44_loss: 0.0822 - val_loss: 0.0909 - val_lambda_1_loss: 0.2444 - val_conv2d_44_loss: 0.0907\n",
      "Epoch 2/250\n",
      "265/265 [==============================] - 409s 2s/step - loss: 0.0795 - lambda_1_loss: 0.2326 - conv2d_44_loss: 0.0794 - val_loss: 0.1020 - val_lambda_1_loss: 0.2451 - val_conv2d_44_loss: 0.1018\n",
      "Epoch 3/250\n",
      "265/265 [==============================] - 412s 2s/step - loss: 0.0762 - lambda_1_loss: 0.2332 - conv2d_44_loss: 0.0760 - val_loss: 0.0941 - val_lambda_1_loss: 0.2505 - val_conv2d_44_loss: 0.0940\n",
      "Epoch 4/250\n",
      "265/265 [==============================] - 419s 2s/step - loss: 0.0757 - lambda_1_loss: 0.2344 - conv2d_44_loss: 0.0755 - val_loss: 0.0898 - val_lambda_1_loss: 0.2515 - val_conv2d_44_loss: 0.0897\n",
      "Epoch 5/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0740 - lambda_1_loss: 0.2375 - conv2d_44_loss: 0.0739 - val_loss: 0.0903 - val_lambda_1_loss: 0.2526 - val_conv2d_44_loss: 0.0902\n",
      "Epoch 6/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0762 - lambda_1_loss: 0.2420 - conv2d_44_loss: 0.0760 - val_loss: 0.0883 - val_lambda_1_loss: 0.2488 - val_conv2d_44_loss: 0.0881\n",
      "Epoch 7/250\n",
      "265/265 [==============================] - 426s 2s/step - loss: 0.0734 - lambda_1_loss: 0.2435 - conv2d_44_loss: 0.0732 - val_loss: 0.0882 - val_lambda_1_loss: 0.2574 - val_conv2d_44_loss: 0.0881\n",
      "Epoch 8/250\n",
      "265/265 [==============================] - 423s 2s/step - loss: 0.0721 - lambda_1_loss: 0.2453 - conv2d_44_loss: 0.0719 - val_loss: 0.0893 - val_lambda_1_loss: 0.2514 - val_conv2d_44_loss: 0.0891\n",
      "Epoch 9/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0733 - lambda_1_loss: 0.2431 - conv2d_44_loss: 0.0732 - val_loss: 0.0857 - val_lambda_1_loss: 0.2515 - val_conv2d_44_loss: 0.0856\n",
      "Epoch 10/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0706 - lambda_1_loss: 0.2458 - conv2d_44_loss: 0.0705 - val_loss: 0.0853 - val_lambda_1_loss: 0.2576 - val_conv2d_44_loss: 0.0852\n",
      "Epoch 11/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0704 - lambda_1_loss: 0.2472 - conv2d_44_loss: 0.0703 - val_loss: 0.0861 - val_lambda_1_loss: 0.2562 - val_conv2d_44_loss: 0.0860\n",
      "Epoch 12/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0707 - lambda_1_loss: 0.2526 - conv2d_44_loss: 0.0705 - val_loss: 0.0963 - val_lambda_1_loss: 0.2550 - val_conv2d_44_loss: 0.0962\n",
      "Epoch 13/250\n",
      "265/265 [==============================] - 425s 2s/step - loss: 0.0706 - lambda_1_loss: 0.2494 - conv2d_44_loss: 0.0704 - val_loss: 0.0857 - val_lambda_1_loss: 0.2642 - val_conv2d_44_loss: 0.0855\n",
      "Epoch 14/250\n",
      "265/265 [==============================] - 425s 2s/step - loss: 0.0688 - lambda_1_loss: 0.2586 - conv2d_44_loss: 0.0686 - val_loss: 0.0837 - val_lambda_1_loss: 0.2727 - val_conv2d_44_loss: 0.0836\n",
      "Epoch 15/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0688 - lambda_1_loss: 0.2576 - conv2d_44_loss: 0.0686 - val_loss: 0.0837 - val_lambda_1_loss: 0.2706 - val_conv2d_44_loss: 0.0835\n",
      "Epoch 16/250\n",
      "265/265 [==============================] - 420s 2s/step - loss: 0.0690 - lambda_1_loss: 0.2566 - conv2d_44_loss: 0.0688 - val_loss: 0.0849 - val_lambda_1_loss: 0.2609 - val_conv2d_44_loss: 0.0848\n",
      "Epoch 17/250\n",
      "265/265 [==============================] - 420s 2s/step - loss: 0.0679 - lambda_1_loss: 0.2612 - conv2d_44_loss: 0.0677 - val_loss: 0.0833 - val_lambda_1_loss: 0.2772 - val_conv2d_44_loss: 0.0831\n",
      "Epoch 18/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0680 - lambda_1_loss: 0.2645 - conv2d_44_loss: 0.0678 - val_loss: 0.0826 - val_lambda_1_loss: 0.2762 - val_conv2d_44_loss: 0.0824\n",
      "Epoch 19/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0679 - lambda_1_loss: 0.2684 - conv2d_44_loss: 0.0677 - val_loss: 0.0851 - val_lambda_1_loss: 0.2828 - val_conv2d_44_loss: 0.0849\n",
      "Epoch 20/250\n",
      "265/265 [==============================] - 429s 2s/step - loss: 0.0672 - lambda_1_loss: 0.2763 - conv2d_44_loss: 0.0670 - val_loss: 0.0828 - val_lambda_1_loss: 0.2984 - val_conv2d_44_loss: 0.0826\n",
      "Epoch 21/250\n",
      "265/265 [==============================] - 425s 2s/step - loss: 0.0697 - lambda_1_loss: 0.2650 - conv2d_44_loss: 0.0695 - val_loss: 0.0824 - val_lambda_1_loss: 0.2758 - val_conv2d_44_loss: 0.0822\n",
      "Epoch 22/250\n",
      "265/265 [==============================] - 427s 2s/step - loss: 0.0672 - lambda_1_loss: 0.2740 - conv2d_44_loss: 0.0670 - val_loss: 0.0824 - val_lambda_1_loss: 0.2814 - val_conv2d_44_loss: 0.0822\n",
      "Epoch 23/250\n",
      "265/265 [==============================] - 423s 2s/step - loss: 0.0659 - lambda_1_loss: 0.2826 - conv2d_44_loss: 0.0656 - val_loss: 0.0816 - val_lambda_1_loss: 0.3059 - val_conv2d_44_loss: 0.0814\n",
      "Epoch 24/250\n",
      "265/265 [==============================] - 421s 2s/step - loss: 0.0673 - lambda_1_loss: 0.2913 - conv2d_44_loss: 0.0671 - val_loss: 0.0828 - val_lambda_1_loss: 0.2897 - val_conv2d_44_loss: 0.0826\n",
      "Epoch 25/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0659 - lambda_1_loss: 0.2951 - conv2d_44_loss: 0.0656 - val_loss: 0.0816 - val_lambda_1_loss: 0.3146 - val_conv2d_44_loss: 0.0813\n",
      "Epoch 26/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0658 - lambda_1_loss: 0.3050 - conv2d_44_loss: 0.0656 - val_loss: 0.0826 - val_lambda_1_loss: 0.3185 - val_conv2d_44_loss: 0.0824\n",
      "Epoch 27/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0656 - lambda_1_loss: 0.3192 - conv2d_44_loss: 0.0653 - val_loss: 0.0813 - val_lambda_1_loss: 0.3300 - val_conv2d_44_loss: 0.0811\n",
      "Epoch 28/250\n",
      "265/265 [==============================] - 429s 2s/step - loss: 0.0659 - lambda_1_loss: 0.3157 - conv2d_44_loss: 0.0657 - val_loss: 0.0821 - val_lambda_1_loss: 0.3363 - val_conv2d_44_loss: 0.0819\n",
      "Epoch 29/250\n",
      "265/265 [==============================] - 432s 2s/step - loss: 0.0659 - lambda_1_loss: 0.3098 - conv2d_44_loss: 0.0656 - val_loss: 0.0817 - val_lambda_1_loss: 0.3239 - val_conv2d_44_loss: 0.0815\n",
      "Epoch 30/250\n",
      "265/265 [==============================] - 428s 2s/step - loss: 0.0657 - lambda_1_loss: 0.3199 - conv2d_44_loss: 0.0654 - val_loss: 0.0822 - val_lambda_1_loss: 0.3171 - val_conv2d_44_loss: 0.0819\n",
      "Epoch 31/250\n",
      "265/265 [==============================] - 421s 2s/step - loss: 0.0663 - lambda_1_loss: 0.3210 - conv2d_44_loss: 0.0660 - val_loss: 0.0815 - val_lambda_1_loss: 0.3283 - val_conv2d_44_loss: 0.0812\n",
      "Epoch 32/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0645 - lambda_1_loss: 0.3260 - conv2d_44_loss: 0.0643 - val_loss: 0.0807 - val_lambda_1_loss: 0.3595 - val_conv2d_44_loss: 0.0804\n",
      "Epoch 33/250\n",
      "265/265 [==============================] - 423s 2s/step - loss: 0.0652 - lambda_1_loss: 0.3399 - conv2d_44_loss: 0.0650 - val_loss: 0.0815 - val_lambda_1_loss: 0.3252 - val_conv2d_44_loss: 0.0812\n",
      "Epoch 34/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0657 - lambda_1_loss: 0.3223 - conv2d_44_loss: 0.0655 - val_loss: 0.0798 - val_lambda_1_loss: 0.3452 - val_conv2d_44_loss: 0.0795\n",
      "Epoch 35/250\n",
      "265/265 [==============================] - 421s 2s/step - loss: 0.0659 - lambda_1_loss: 0.3271 - conv2d_44_loss: 0.0657 - val_loss: 0.0803 - val_lambda_1_loss: 0.3432 - val_conv2d_44_loss: 0.0800\n",
      "Epoch 36/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0647 - lambda_1_loss: 0.3341 - conv2d_44_loss: 0.0644 - val_loss: 0.0803 - val_lambda_1_loss: 0.3421 - val_conv2d_44_loss: 0.0801\n",
      "Epoch 37/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0644 - lambda_1_loss: 0.3336 - conv2d_44_loss: 0.0641 - val_loss: 0.0825 - val_lambda_1_loss: 0.3499 - val_conv2d_44_loss: 0.0822\n",
      "Epoch 38/250\n",
      "265/265 [==============================] - 420s 2s/step - loss: 0.0644 - lambda_1_loss: 0.3515 - conv2d_44_loss: 0.0641 - val_loss: 0.0862 - val_lambda_1_loss: 0.3484 - val_conv2d_44_loss: 0.0860\n",
      "Epoch 39/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 416s 2s/step - loss: 0.0649 - lambda_1_loss: 0.3415 - conv2d_44_loss: 0.0646 - val_loss: 0.0823 - val_lambda_1_loss: 0.3522 - val_conv2d_44_loss: 0.0821\n",
      "Epoch 40/250\n",
      "265/265 [==============================] - 416s 2s/step - loss: 0.0633 - lambda_1_loss: 0.3567 - conv2d_44_loss: 0.0630 - val_loss: 0.0815 - val_lambda_1_loss: 0.3713 - val_conv2d_44_loss: 0.0812\n",
      "Epoch 41/250\n",
      "265/265 [==============================] - 413s 2s/step - loss: 0.0640 - lambda_1_loss: 0.3600 - conv2d_44_loss: 0.0637 - val_loss: 0.0827 - val_lambda_1_loss: 0.3760 - val_conv2d_44_loss: 0.0824\n",
      "Epoch 42/250\n",
      "265/265 [==============================] - 412s 2s/step - loss: 0.0643 - lambda_1_loss: 0.3663 - conv2d_44_loss: 0.0640 - val_loss: 0.0800 - val_lambda_1_loss: 0.3661 - val_conv2d_44_loss: 0.0797\n",
      "Epoch 43/250\n",
      "265/265 [==============================] - 417s 2s/step - loss: 0.0638 - lambda_1_loss: 0.3647 - conv2d_44_loss: 0.0635 - val_loss: 0.0793 - val_lambda_1_loss: 0.3882 - val_conv2d_44_loss: 0.0790\n",
      "Epoch 44/250\n",
      "265/265 [==============================] - 414s 2s/step - loss: 0.0638 - lambda_1_loss: 0.3714 - conv2d_44_loss: 0.0635 - val_loss: 0.0811 - val_lambda_1_loss: 0.3804 - val_conv2d_44_loss: 0.0808\n",
      "Epoch 45/250\n",
      "265/265 [==============================] - 415s 2s/step - loss: 0.0634 - lambda_1_loss: 0.3733 - conv2d_44_loss: 0.0631 - val_loss: 0.0791 - val_lambda_1_loss: 0.3942 - val_conv2d_44_loss: 0.0788\n",
      "Epoch 46/250\n",
      "265/265 [==============================] - 414s 2s/step - loss: 0.0638 - lambda_1_loss: 0.3741 - conv2d_44_loss: 0.0635 - val_loss: 0.0811 - val_lambda_1_loss: 0.3705 - val_conv2d_44_loss: 0.0808\n",
      "Epoch 47/250\n",
      "265/265 [==============================] - 415s 2s/step - loss: 0.0641 - lambda_1_loss: 0.3712 - conv2d_44_loss: 0.0638 - val_loss: 0.0805 - val_lambda_1_loss: 0.3837 - val_conv2d_44_loss: 0.0802\n",
      "Epoch 48/250\n",
      "265/265 [==============================] - 412s 2s/step - loss: 0.0633 - lambda_1_loss: 0.3754 - conv2d_44_loss: 0.0630 - val_loss: 0.0798 - val_lambda_1_loss: 0.3957 - val_conv2d_44_loss: 0.0795\n",
      "Epoch 49/250\n",
      "265/265 [==============================] - 412s 2s/step - loss: 0.0636 - lambda_1_loss: 0.3809 - conv2d_44_loss: 0.0633 - val_loss: 0.0789 - val_lambda_1_loss: 0.3967 - val_conv2d_44_loss: 0.0785\n",
      "Epoch 50/250\n",
      "265/265 [==============================] - 421s 2s/step - loss: 0.0637 - lambda_1_loss: 0.3794 - conv2d_44_loss: 0.0634 - val_loss: 0.0797 - val_lambda_1_loss: 0.3880 - val_conv2d_44_loss: 0.0794\n",
      "Epoch 51/250\n",
      "265/265 [==============================] - 419s 2s/step - loss: 0.0633 - lambda_1_loss: 0.3865 - conv2d_44_loss: 0.0630 - val_loss: 0.0794 - val_lambda_1_loss: 0.4010 - val_conv2d_44_loss: 0.0791\n",
      "Epoch 52/250\n",
      "265/265 [==============================] - 415s 2s/step - loss: 0.0632 - lambda_1_loss: 0.3864 - conv2d_44_loss: 0.0629 - val_loss: 0.0806 - val_lambda_1_loss: 0.3991 - val_conv2d_44_loss: 0.0802\n",
      "Epoch 53/250\n",
      "265/265 [==============================] - 412s 2s/step - loss: 0.0629 - lambda_1_loss: 0.3988 - conv2d_44_loss: 0.0626 - val_loss: 0.0830 - val_lambda_1_loss: 0.4192 - val_conv2d_44_loss: 0.0826\n",
      "Epoch 54/250\n",
      "265/265 [==============================] - 416s 2s/step - loss: 0.0634 - lambda_1_loss: 0.3985 - conv2d_44_loss: 0.0631 - val_loss: 0.0791 - val_lambda_1_loss: 0.4209 - val_conv2d_44_loss: 0.0787\n",
      "Epoch 55/250\n",
      "265/265 [==============================] - 413s 2s/step - loss: 0.0635 - lambda_1_loss: 0.4070 - conv2d_44_loss: 0.0632 - val_loss: 0.0814 - val_lambda_1_loss: 0.4157 - val_conv2d_44_loss: 0.0811\n",
      "Epoch 56/250\n",
      "265/265 [==============================] - 415s 2s/step - loss: 0.0633 - lambda_1_loss: 0.4022 - conv2d_44_loss: 0.0629 - val_loss: 0.0786 - val_lambda_1_loss: 0.4265 - val_conv2d_44_loss: 0.0783\n",
      "Epoch 57/250\n",
      "265/265 [==============================] - 413s 2s/step - loss: 0.0638 - lambda_1_loss: 0.4067 - conv2d_44_loss: 0.0635 - val_loss: 0.0797 - val_lambda_1_loss: 0.4214 - val_conv2d_44_loss: 0.0793\n",
      "Epoch 58/250\n",
      "265/265 [==============================] - 410s 2s/step - loss: 0.0628 - lambda_1_loss: 0.4162 - conv2d_44_loss: 0.0625 - val_loss: 0.0795 - val_lambda_1_loss: 0.4352 - val_conv2d_44_loss: 0.0792\n",
      "Epoch 59/250\n",
      "265/265 [==============================] - 412s 2s/step - loss: 0.0634 - lambda_1_loss: 0.4200 - conv2d_44_loss: 0.0630 - val_loss: 0.0800 - val_lambda_1_loss: 0.4098 - val_conv2d_44_loss: 0.0797\n",
      "Epoch 60/250\n",
      "265/265 [==============================] - 416s 2s/step - loss: 0.0628 - lambda_1_loss: 0.4131 - conv2d_44_loss: 0.0624 - val_loss: 0.0790 - val_lambda_1_loss: 0.4173 - val_conv2d_44_loss: 0.0787\n",
      "Epoch 61/250\n",
      "265/265 [==============================] - 413s 2s/step - loss: 0.0622 - lambda_1_loss: 0.4184 - conv2d_44_loss: 0.0619 - val_loss: 0.0779 - val_lambda_1_loss: 0.4363 - val_conv2d_44_loss: 0.0776\n",
      "Epoch 62/250\n",
      "265/265 [==============================] - 414s 2s/step - loss: 0.0633 - lambda_1_loss: 0.4217 - conv2d_44_loss: 0.0630 - val_loss: 0.0797 - val_lambda_1_loss: 0.4237 - val_conv2d_44_loss: 0.0794\n",
      "Epoch 63/250\n",
      "265/265 [==============================] - 415s 2s/step - loss: 0.0620 - lambda_1_loss: 0.4184 - conv2d_44_loss: 0.0616 - val_loss: 0.0792 - val_lambda_1_loss: 0.4423 - val_conv2d_44_loss: 0.0789\n",
      "Epoch 64/250\n",
      "265/265 [==============================] - 411s 2s/step - loss: 0.0626 - lambda_1_loss: 0.4262 - conv2d_44_loss: 0.0622 - val_loss: 0.0791 - val_lambda_1_loss: 0.4424 - val_conv2d_44_loss: 0.0788\n",
      "Epoch 65/250\n",
      "265/265 [==============================] - 414s 2s/step - loss: 0.0624 - lambda_1_loss: 0.4293 - conv2d_44_loss: 0.0620 - val_loss: 0.0786 - val_lambda_1_loss: 0.4442 - val_conv2d_44_loss: 0.0782\n",
      "Epoch 66/250\n",
      "265/265 [==============================] - 412s 2s/step - loss: 0.0625 - lambda_1_loss: 0.4298 - conv2d_44_loss: 0.0621 - val_loss: 0.0804 - val_lambda_1_loss: 0.4437 - val_conv2d_44_loss: 0.0800\n",
      "Epoch 67/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0630 - lambda_1_loss: 0.4276 - conv2d_44_loss: 0.0626 - val_loss: 0.0781 - val_lambda_1_loss: 0.4369 - val_conv2d_44_loss: 0.0778\n",
      "Epoch 68/250\n",
      "265/265 [==============================] - 421s 2s/step - loss: 0.0624 - lambda_1_loss: 0.4352 - conv2d_44_loss: 0.0620 - val_loss: 0.0830 - val_lambda_1_loss: 0.4360 - val_conv2d_44_loss: 0.0827\n",
      "Epoch 69/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0624 - lambda_1_loss: 0.4223 - conv2d_44_loss: 0.0621 - val_loss: 0.0815 - val_lambda_1_loss: 0.4392 - val_conv2d_44_loss: 0.0812\n",
      "Epoch 70/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0622 - lambda_1_loss: 0.4386 - conv2d_44_loss: 0.0618 - val_loss: 0.0789 - val_lambda_1_loss: 0.4466 - val_conv2d_44_loss: 0.0785\n",
      "Epoch 71/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0618 - lambda_1_loss: 0.4407 - conv2d_44_loss: 0.0614 - val_loss: 0.0779 - val_lambda_1_loss: 0.4698 - val_conv2d_44_loss: 0.0775\n",
      "Epoch 72/250\n",
      "265/265 [==============================] - 410s 2s/step - loss: 0.0628 - lambda_1_loss: 0.4418 - conv2d_44_loss: 0.0625 - val_loss: 0.0791 - val_lambda_1_loss: 0.4446 - val_conv2d_44_loss: 0.0787\n",
      "Epoch 73/250\n",
      "265/265 [==============================] - 414s 2s/step - loss: 0.0622 - lambda_1_loss: 0.4482 - conv2d_44_loss: 0.0618 - val_loss: 0.0804 - val_lambda_1_loss: 0.4536 - val_conv2d_44_loss: 0.0800\n",
      "Epoch 74/250\n",
      "265/265 [==============================] - 415s 2s/step - loss: 0.0623 - lambda_1_loss: 0.4476 - conv2d_44_loss: 0.0619 - val_loss: 0.0783 - val_lambda_1_loss: 0.4602 - val_conv2d_44_loss: 0.0780\n",
      "Epoch 75/250\n",
      "265/265 [==============================] - 412s 2s/step - loss: 0.0616 - lambda_1_loss: 0.4516 - conv2d_44_loss: 0.0612 - val_loss: 0.0794 - val_lambda_1_loss: 0.4740 - val_conv2d_44_loss: 0.0790\n",
      "Epoch 76/250\n",
      "265/265 [==============================] - 413s 2s/step - loss: 0.0628 - lambda_1_loss: 0.4471 - conv2d_44_loss: 0.0624 - val_loss: 0.0814 - val_lambda_1_loss: 0.4475 - val_conv2d_44_loss: 0.0811\n",
      "Epoch 77/250\n",
      "265/265 [==============================] - 421s 2s/step - loss: 0.0618 - lambda_1_loss: 0.4448 - conv2d_44_loss: 0.0615 - val_loss: 0.0775 - val_lambda_1_loss: 0.4649 - val_conv2d_44_loss: 0.0771\n",
      "Epoch 78/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 421s 2s/step - loss: 0.0628 - lambda_1_loss: 0.4638 - conv2d_44_loss: 0.0624 - val_loss: 0.0841 - val_lambda_1_loss: 0.4698 - val_conv2d_44_loss: 0.0837\n",
      "Epoch 79/250\n",
      "265/265 [==============================] - 417s 2s/step - loss: 0.0630 - lambda_1_loss: 0.4663 - conv2d_44_loss: 0.0626 - val_loss: 0.0804 - val_lambda_1_loss: 0.4615 - val_conv2d_44_loss: 0.0800\n",
      "Epoch 80/250\n",
      "265/265 [==============================] - 413s 2s/step - loss: 0.0620 - lambda_1_loss: 0.4629 - conv2d_44_loss: 0.0616 - val_loss: 0.0778 - val_lambda_1_loss: 0.4981 - val_conv2d_44_loss: 0.0774\n",
      "Epoch 81/250\n",
      "265/265 [==============================] - 414s 2s/step - loss: 0.0617 - lambda_1_loss: 0.4670 - conv2d_44_loss: 0.0613 - val_loss: 0.0781 - val_lambda_1_loss: 0.4842 - val_conv2d_44_loss: 0.0777\n",
      "Epoch 82/250\n",
      "265/265 [==============================] - 426s 2s/step - loss: 0.0617 - lambda_1_loss: 0.4702 - conv2d_44_loss: 0.0613 - val_loss: 0.0775 - val_lambda_1_loss: 0.4785 - val_conv2d_44_loss: 0.0771\n",
      "Epoch 83/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0617 - lambda_1_loss: 0.4708 - conv2d_44_loss: 0.0613 - val_loss: 0.0783 - val_lambda_1_loss: 0.4761 - val_conv2d_44_loss: 0.0779\n",
      "Epoch 84/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0616 - lambda_1_loss: 0.4695 - conv2d_44_loss: 0.0612 - val_loss: 0.0775 - val_lambda_1_loss: 0.4925 - val_conv2d_44_loss: 0.0771\n",
      "Epoch 85/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0623 - lambda_1_loss: 0.4721 - conv2d_44_loss: 0.0619 - val_loss: 0.0784 - val_lambda_1_loss: 0.4784 - val_conv2d_44_loss: 0.0780\n",
      "Epoch 86/250\n",
      "265/265 [==============================] - 423s 2s/step - loss: 0.0611 - lambda_1_loss: 0.4637 - conv2d_44_loss: 0.0607 - val_loss: 0.0778 - val_lambda_1_loss: 0.4953 - val_conv2d_44_loss: 0.0773\n",
      "Epoch 87/250\n",
      "265/265 [==============================] - 436s 2s/step - loss: 0.0611 - lambda_1_loss: 0.4794 - conv2d_44_loss: 0.0607 - val_loss: 0.0780 - val_lambda_1_loss: 0.4942 - val_conv2d_44_loss: 0.0776\n",
      "Epoch 88/250\n",
      "265/265 [==============================] - 434s 2s/step - loss: 0.0619 - lambda_1_loss: 0.4703 - conv2d_44_loss: 0.0615 - val_loss: 0.0770 - val_lambda_1_loss: 0.4900 - val_conv2d_44_loss: 0.0766\n",
      "Epoch 89/250\n",
      "265/265 [==============================] - 434s 2s/step - loss: 0.0624 - lambda_1_loss: 0.4679 - conv2d_44_loss: 0.0620 - val_loss: 0.0781 - val_lambda_1_loss: 0.4816 - val_conv2d_44_loss: 0.0777\n",
      "Epoch 90/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0614 - lambda_1_loss: 0.4694 - conv2d_44_loss: 0.0610 - val_loss: 0.0779 - val_lambda_1_loss: 0.4806 - val_conv2d_44_loss: 0.0775\n",
      "Epoch 91/250\n",
      "265/265 [==============================] - 423s 2s/step - loss: 0.0610 - lambda_1_loss: 0.4775 - conv2d_44_loss: 0.0606 - val_loss: 0.0776 - val_lambda_1_loss: 0.4953 - val_conv2d_44_loss: 0.0772\n",
      "Epoch 92/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0622 - lambda_1_loss: 0.4784 - conv2d_44_loss: 0.0618 - val_loss: 0.0777 - val_lambda_1_loss: 0.4944 - val_conv2d_44_loss: 0.0773\n",
      "Epoch 93/250\n",
      "265/265 [==============================] - 426s 2s/step - loss: 0.0611 - lambda_1_loss: 0.4761 - conv2d_44_loss: 0.0607 - val_loss: 0.0797 - val_lambda_1_loss: 0.4940 - val_conv2d_44_loss: 0.0793\n",
      "Epoch 94/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0614 - lambda_1_loss: 0.4819 - conv2d_44_loss: 0.0610 - val_loss: 0.0796 - val_lambda_1_loss: 0.4977 - val_conv2d_44_loss: 0.0792\n",
      "Epoch 95/250\n",
      "265/265 [==============================] - 431s 2s/step - loss: 0.0617 - lambda_1_loss: 0.4819 - conv2d_44_loss: 0.0613 - val_loss: 0.0777 - val_lambda_1_loss: 0.4935 - val_conv2d_44_loss: 0.0773\n",
      "Epoch 96/250\n",
      "265/265 [==============================] - 428s 2s/step - loss: 0.0612 - lambda_1_loss: 0.4799 - conv2d_44_loss: 0.0608 - val_loss: 0.0773 - val_lambda_1_loss: 0.4976 - val_conv2d_44_loss: 0.0769\n",
      "Epoch 97/250\n",
      "265/265 [==============================] - 425s 2s/step - loss: 0.0623 - lambda_1_loss: 0.4803 - conv2d_44_loss: 0.0619 - val_loss: 0.0773 - val_lambda_1_loss: 0.4920 - val_conv2d_44_loss: 0.0768\n",
      "Epoch 98/250\n",
      "265/265 [==============================] - 423s 2s/step - loss: 0.0608 - lambda_1_loss: 0.4783 - conv2d_44_loss: 0.0604 - val_loss: 0.0775 - val_lambda_1_loss: 0.5088 - val_conv2d_44_loss: 0.0771\n",
      "Epoch 99/250\n",
      "265/265 [==============================] - 426s 2s/step - loss: 0.0616 - lambda_1_loss: 0.4868 - conv2d_44_loss: 0.0612 - val_loss: 0.0775 - val_lambda_1_loss: 0.5088 - val_conv2d_44_loss: 0.0770\n",
      "Epoch 100/250\n",
      "265/265 [==============================] - 425s 2s/step - loss: 0.0613 - lambda_1_loss: 0.4903 - conv2d_44_loss: 0.0608 - val_loss: 0.0776 - val_lambda_1_loss: 0.5056 - val_conv2d_44_loss: 0.0772\n",
      "Epoch 101/250\n",
      "265/265 [==============================] - 425s 2s/step - loss: 0.0612 - lambda_1_loss: 0.4975 - conv2d_44_loss: 0.0608 - val_loss: 0.0782 - val_lambda_1_loss: 0.5032 - val_conv2d_44_loss: 0.0778\n",
      "Epoch 102/250\n",
      "265/265 [==============================] - 425s 2s/step - loss: 0.0616 - lambda_1_loss: 0.4792 - conv2d_44_loss: 0.0612 - val_loss: 0.0768 - val_lambda_1_loss: 0.5027 - val_conv2d_44_loss: 0.0764\n",
      "Epoch 103/250\n",
      "265/265 [==============================] - 423s 2s/step - loss: 0.0610 - lambda_1_loss: 0.5024 - conv2d_44_loss: 0.0605 - val_loss: 0.0767 - val_lambda_1_loss: 0.5200 - val_conv2d_44_loss: 0.0762\n",
      "Epoch 104/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0611 - lambda_1_loss: 0.4944 - conv2d_44_loss: 0.0607 - val_loss: 0.0782 - val_lambda_1_loss: 0.5068 - val_conv2d_44_loss: 0.0778\n",
      "Epoch 105/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0614 - lambda_1_loss: 0.4930 - conv2d_44_loss: 0.0609 - val_loss: 0.0790 - val_lambda_1_loss: 0.5124 - val_conv2d_44_loss: 0.0786\n",
      "Epoch 106/250\n",
      "265/265 [==============================] - 424s 2s/step - loss: 0.0609 - lambda_1_loss: 0.4993 - conv2d_44_loss: 0.0605 - val_loss: 0.0768 - val_lambda_1_loss: 0.5239 - val_conv2d_44_loss: 0.0763\n",
      "Epoch 107/250\n",
      "265/265 [==============================] - 433s 2s/step - loss: 0.0609 - lambda_1_loss: 0.4977 - conv2d_44_loss: 0.0605 - val_loss: 0.0780 - val_lambda_1_loss: 0.5223 - val_conv2d_44_loss: 0.0775\n",
      "Epoch 108/250\n",
      "265/265 [==============================] - 430s 2s/step - loss: 0.0616 - lambda_1_loss: 0.4954 - conv2d_44_loss: 0.0611 - val_loss: 0.0771 - val_lambda_1_loss: 0.5150 - val_conv2d_44_loss: 0.0767\n",
      "Epoch 109/250\n",
      "265/265 [==============================] - 425s 2s/step - loss: 0.0610 - lambda_1_loss: 0.5038 - conv2d_44_loss: 0.0605 - val_loss: 0.0770 - val_lambda_1_loss: 0.5165 - val_conv2d_44_loss: 0.0766\n",
      "Epoch 110/250\n",
      "265/265 [==============================] - 426s 2s/step - loss: 0.0605 - lambda_1_loss: 0.5025 - conv2d_44_loss: 0.0601 - val_loss: 0.0782 - val_lambda_1_loss: 0.5273 - val_conv2d_44_loss: 0.0777\n",
      "Epoch 111/250\n",
      "265/265 [==============================] - 426s 2s/step - loss: 0.0609 - lambda_1_loss: 0.5147 - conv2d_44_loss: 0.0604 - val_loss: 0.0768 - val_lambda_1_loss: 0.5269 - val_conv2d_44_loss: 0.0764\n",
      "Epoch 112/250\n",
      "265/265 [==============================] - 423s 2s/step - loss: 0.0612 - lambda_1_loss: 0.5070 - conv2d_44_loss: 0.0607 - val_loss: 0.0770 - val_lambda_1_loss: 0.5313 - val_conv2d_44_loss: 0.0765\n",
      "Epoch 113/250\n",
      "265/265 [==============================] - 425s 2s/step - loss: 0.0612 - lambda_1_loss: 0.5175 - conv2d_44_loss: 0.0607 - val_loss: 0.0768 - val_lambda_1_loss: 0.5325 - val_conv2d_44_loss: 0.0763\n",
      "Epoch 114/250\n",
      "265/265 [==============================] - 432s 2s/step - loss: 0.0621 - lambda_1_loss: 0.5164 - conv2d_44_loss: 0.0616 - val_loss: 0.0832 - val_lambda_1_loss: 0.5094 - val_conv2d_44_loss: 0.0827\n",
      "Epoch 115/250\n",
      "265/265 [==============================] - 428s 2s/step - loss: 0.0609 - lambda_1_loss: 0.4970 - conv2d_44_loss: 0.0605 - val_loss: 0.0772 - val_lambda_1_loss: 0.5182 - val_conv2d_44_loss: 0.0768\n",
      "Epoch 116/250\n",
      "265/265 [==============================] - 426s 2s/step - loss: 0.0608 - lambda_1_loss: 0.5031 - conv2d_44_loss: 0.0604 - val_loss: 0.0769 - val_lambda_1_loss: 0.5266 - val_conv2d_44_loss: 0.0765\n",
      "Epoch 117/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 413s 2s/step - loss: 0.0604 - lambda_1_loss: 0.5165 - conv2d_44_loss: 0.0600 - val_loss: 0.0769 - val_lambda_1_loss: 0.5405 - val_conv2d_44_loss: 0.0764\n",
      "Epoch 118/250\n",
      "265/265 [==============================] - 414s 2s/step - loss: 0.0608 - lambda_1_loss: 0.5151 - conv2d_44_loss: 0.0604 - val_loss: 0.0767 - val_lambda_1_loss: 0.5416 - val_conv2d_44_loss: 0.0762\n",
      "Epoch 119/250\n",
      "265/265 [==============================] - 413s 2s/step - loss: 0.0609 - lambda_1_loss: 0.5223 - conv2d_44_loss: 0.0605 - val_loss: 0.0776 - val_lambda_1_loss: 0.5398 - val_conv2d_44_loss: 0.0772\n",
      "Epoch 120/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0606 - lambda_1_loss: 0.5220 - conv2d_44_loss: 0.0602 - val_loss: 0.0806 - val_lambda_1_loss: 0.5270 - val_conv2d_44_loss: 0.0802\n",
      "Epoch 121/250\n",
      "265/265 [==============================] - 423s 2s/step - loss: 0.0609 - lambda_1_loss: 0.5217 - conv2d_44_loss: 0.0604 - val_loss: 0.0770 - val_lambda_1_loss: 0.5400 - val_conv2d_44_loss: 0.0765\n",
      "Epoch 122/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0605 - lambda_1_loss: 0.5150 - conv2d_44_loss: 0.0600 - val_loss: 0.0777 - val_lambda_1_loss: 0.5395 - val_conv2d_44_loss: 0.0772\n",
      "Epoch 123/250\n",
      "265/265 [==============================] - 422s 2s/step - loss: 0.0613 - lambda_1_loss: 0.5369 - conv2d_44_loss: 0.0608 - val_loss: 0.0801 - val_lambda_1_loss: 0.5400 - val_conv2d_44_loss: 0.0796\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(combined,\n",
    "                 epochs=epochs,\n",
    "                 steps_per_epoch=rec_train.shape[0] / batch_size,\n",
    "                 verbose=1,\n",
    "                 validation_data= (kspace_val,[kspace_val2,rec_val]),\n",
    "                 callbacks=[checkpoint,earlyStopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
